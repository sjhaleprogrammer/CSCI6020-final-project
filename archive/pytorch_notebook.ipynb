{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ff7010-1687-406a-a9ef-5ef72901aca0",
   "metadata": {},
   "source": [
    "# This notebook uses the pytorch Kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b6b98c-6ee6-4be2-9ccc-51ea25c0228d",
   "metadata": {},
   "source": [
    "### Verify the Correct Conda Environment and Pytorch is GPU ready! (if this doesnt pass then fix before moving forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049e8dd3-69aa-4062-845a-87b3b36a9882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is available\n",
      "CUDA version: 11.8\n",
      "PyTorch CUDA version: 11.8\n",
      "Number of GPUs: 1\n",
      "Device name: NVIDIA GeForce RTX 3070\n",
      "\n",
      "`nvidia-smi` is available:\n",
      "\n",
      "Sun Nov 24 13:17:40 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070        Off |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   53C    P8             19W /  220W |    1263MiB /   8192MiB |     12%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3514      G   /usr/lib/xorg/Xorg                            710MiB |\n",
      "|    0   N/A  N/A      3647      G   /usr/bin/gnome-shell                          121MiB |\n",
      "|    0   N/A  N/A      4473      G   ...ures=SpareRendererForSitePerProcess         31MiB |\n",
      "|    0   N/A  N/A      4822      G   ...yOnDemand --variations-seed-version         42MiB |\n",
      "|    0   N/A  N/A      6903      G   /usr/bin/nextcloud                             35MiB |\n",
      "|    0   N/A  N/A     10287      G   ...c27950db056eae83bc37827ee14c99cb0a0        188MiB |\n",
      "|    0   N/A  N/A     11762      G   ...erProcess --variations-seed-version        114MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "Running a simple tensor operation on the GPU...\n",
      "GPU test passed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "def is_cuda_installed():\n",
    "    \"\"\"\n",
    "    Check if `nvidia-smi` is installed and available.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (bool, str)\n",
    "            - True if `nvidia-smi` is available, False otherwise.\n",
    "            - Output of `nvidia-smi` if available, otherwise an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout\n",
    "        return False, result.stderr\n",
    "    except FileNotFoundError:\n",
    "        return False, \"nvidia-smi not found. Ensure the NVIDIA drivers are properly installed.\"\n",
    "\n",
    "# Check GPU, CUDA, and PyTorch setup\n",
    "def run_gpu_test():\n",
    "    \"\"\"\n",
    "    Checks for an available GPU, prints useful info to stdout, and runs a simple test.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if GPU is available and test passes, False otherwise.\n",
    "    \"\"\"\n",
    "    # Check if CUDA is available\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"GPU is not available\")\n",
    "        return False\n",
    "\n",
    "    print(\"\\nGPU is available\")\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"PyTorch CUDA version:\", torch.version.cuda)\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "    # Check `nvidia-smi`\n",
    "    installed, output = is_cuda_installed()\n",
    "    if not installed:\n",
    "        print(\"\\n`nvidia-smi` is not installed or not found.\\n\"\n",
    "              \"Please see https://docs.nvidia.com/cuda/cuda-installation-guide-linux/\")\n",
    "        return False\n",
    "    print(\"\\n`nvidia-smi` is available:\\n\")\n",
    "    print(output)\n",
    "\n",
    "    # Run a simple PyTorch tensor operation on GPU\n",
    "    print(\"Running a simple tensor operation on the GPU...\")\n",
    "    try:\n",
    "        x = torch.rand(10000, 10000, device='cuda')\n",
    "        y = torch.mm(x, x)\n",
    "        print(\"GPU test passed successfully!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"GPU test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "run_gpu_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47111024-9e0b-4f53-9fff-d72147fffa81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
