{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58de91d7-ea13-40dc-a687-916268474d8c",
   "metadata": {},
   "source": [
    "# This is our testing notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba277e-76b2-4ddc-ab52-9101fc4d3898",
   "metadata": {},
   "source": [
    "### The concept here is to have a reusable series of tests, for testing the integration of our ML models into the application. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca8563-bd18-4a16-b2d6-f92c0948531f",
   "metadata": {},
   "source": [
    "### Verify that Nvidia drivers, Cuda, and Pytorch are functional and GPU ready! (if this doesnt pass then fix your system before working with the Neural Network model, everything else should work fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c9107b-005d-48e9-8637-1ead096d49e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is available\n",
      "CUDA version: 11.8\n",
      "PyTorch CUDA version: 11.8\n",
      "Number of GPUs: 1\n",
      "Device name: NVIDIA GeForce RTX 3070\n",
      "\n",
      "`nvidia-smi` is available:\n",
      "\n",
      "Sun Nov 24 13:24:29 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070        Off |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   53C    P8             19W /  220W |    2213MiB /   8192MiB |      3%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3514      G   /usr/lib/xorg/Xorg                            710MiB |\n",
      "|    0   N/A  N/A      3647      G   /usr/bin/gnome-shell                          121MiB |\n",
      "|    0   N/A  N/A      4473      G   ...ures=SpareRendererForSitePerProcess         31MiB |\n",
      "|    0   N/A  N/A      4822      G   ...yOnDemand --variations-seed-version         48MiB |\n",
      "|    0   N/A  N/A      6903      G   /usr/bin/nextcloud                             35MiB |\n",
      "|    0   N/A  N/A     10287      G   ...c27950db056eae83bc37827ee14c99cb0a0        190MiB |\n",
      "|    0   N/A  N/A     11762      G   ...erProcess --variations-seed-version        106MiB |\n",
      "|    0   N/A  N/A    134711      C   ...aconda3/envs/pytorch_env/bin/python        948MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "Running a simple tensor operation on the GPU...\n",
      "GPU test passed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "def is_cuda_installed():\n",
    "    \"\"\"\n",
    "    Check if `nvidia-smi` is installed and available.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (bool, str)\n",
    "            - True if `nvidia-smi` is available, False otherwise.\n",
    "            - Output of `nvidia-smi` if available, otherwise an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout\n",
    "        return False, result.stderr\n",
    "    except FileNotFoundError:\n",
    "        return False, \"nvidia-smi not found. Ensure the NVIDIA drivers are properly installed.\"\n",
    "\n",
    "# Check GPU, CUDA, and PyTorch setup\n",
    "def run_gpu_test():\n",
    "    \"\"\"\n",
    "    Checks for an available GPU, prints useful info to stdout, and runs a simple test.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if GPU is available and test passes, False otherwise.\n",
    "    \"\"\"\n",
    "    # Check if CUDA is available\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"GPU is not available\")\n",
    "        return False\n",
    "\n",
    "    print(\"\\nGPU is available\")\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"PyTorch CUDA version:\", torch.version.cuda)\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "    # Check `nvidia-smi`\n",
    "    installed, output = is_cuda_installed()\n",
    "    if not installed:\n",
    "        print(\"\\n`nvidia-smi` is not installed or not found.\\n\"\n",
    "              \"Please see https://docs.nvidia.com/cuda/cuda-installation-guide-linux/\")\n",
    "        return False\n",
    "    print(\"\\n`nvidia-smi` is available:\\n\")\n",
    "    print(output)\n",
    "\n",
    "    # Run a simple PyTorch tensor operation on GPU\n",
    "    print(\"Running a simple tensor operation on the GPU...\")\n",
    "    try:\n",
    "        x = torch.rand(10000, 10000, device='cuda')\n",
    "        y = torch.mm(x, x)\n",
    "        print(\"GPU test passed successfully!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"GPU test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "run_gpu_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3b0619-8df0-4697-b52c-a13beab1ff67",
   "metadata": {},
   "source": [
    "### This block tests inference.py script and trained models for functionality, before attempting to tie it into the front end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b0ea05-baa6-4f36-b738-5a1f485e4ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model: logistic_regression\n",
      "Predicting for California (2024) using logistic_regression...\n",
      "Predicted Election Result: Democratic\n",
      "\n",
      "Predicting for Texas (2024) using logistic_regression...\n",
      "Predicted Election Result: Republican\n",
      "\n",
      "Predicting for Nevada (2024) using logistic_regression...\n",
      "Predicted Election Result: Republican\n",
      "\n",
      "Predicting for Florida (2024) using logistic_regression...\n",
      "Predicted Election Result: Republican\n",
      "\n",
      "\n",
      "Testing model: k_nearest_neighbors\n",
      "Predicting for California (2024) using k_nearest_neighbors...\n",
      "Predicted Election Result: Democratic\n",
      "\n",
      "Predicting for Texas (2024) using k_nearest_neighbors...\n",
      "Predicted Election Result: Republican\n",
      "\n",
      "Predicting for Nevada (2024) using k_nearest_neighbors...\n",
      "Predicted Election Result: Democratic\n",
      "\n",
      "Predicting for Florida (2024) using k_nearest_neighbors...\n",
      "Predicted Election Result: Republican\n",
      "\n",
      "\n",
      "Testing model: decision_tree\n",
      "Predicting for California (2024) using decision_tree...\n",
      "Predicted Election Result: Democratic\n",
      "\n",
      "Predicting for Texas (2024) using decision_tree...\n",
      "Predicted Election Result: Democratic\n",
      "\n",
      "Predicting for Nevada (2024) using decision_tree...\n",
      "Predicted Election Result: Republican\n",
      "\n",
      "Predicting for Florida (2024) using decision_tree...\n",
      "Predicted Election Result: Democratic\n",
      "\n",
      "\n",
      "Testing model: random_forest\n",
      "Predicting for California (2024) using random_forest...\n",
      "Predicted Election Result: Democratic\n",
      "\n",
      "Predicting for Texas (2024) using random_forest...\n",
      "Predicted Election Result: Democratic\n",
      "\n",
      "Predicting for Nevada (2024) using random_forest...\n",
      "Predicted Election Result: Democratic\n",
      "\n",
      "Predicting for Florida (2024) using random_forest...\n",
      "Predicted Election Result: Republican\n",
      "\n",
      "\n",
      "Testing model: neural_network\n",
      "Predicting for California (2024) using neural_network...\n",
      "Predicted Election Result: Democratic\n",
      "\n",
      "Predicting for Texas (2024) using neural_network...\n",
      "Predicted Election Result: Republican\n",
      "\n",
      "Predicting for Nevada (2024) using neural_network...\n",
      "Predicted Election Result: Republican\n",
      "\n",
      "Predicting for Florida (2024) using neural_network...\n",
      "Predicted Election Result: Republican\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../python')  # Ensure the python folder is in the module path\n",
    "from inference import predict_election_from_state\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Add all models to the list of models to test\n",
    "    test_models = [\n",
    "        \"logistic_regression\",\n",
    "        \"k_nearest_neighbors\",\n",
    "        \"decision_tree\",\n",
    "        \"random_forest\",\n",
    "        \"neural_network\",\n",
    "    ]\n",
    "\n",
    "    test_cases = [\n",
    "        {'state': 'California', 'year': 2024},\n",
    "        {'state': 'Texas', 'year': 2024},\n",
    "        {'state': 'Nevada', 'year': 2024},\n",
    "        {'state': 'Florida', 'year': 2024},\n",
    "    ]\n",
    "\n",
    "    for model_name in test_models:\n",
    "        print(f\"\\nTesting model: {model_name}\")\n",
    "        for case in test_cases:\n",
    "            try:\n",
    "                state = case['state']\n",
    "                year = case['year']\n",
    "                print(f\"Predicting for {state} ({year}) using {model_name}...\")\n",
    "                result = predict_election_from_state(model_name, state, year)\n",
    "                print(f\"Predicted Election Result: {result}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb184c-e61a-46a9-b0bb-3a37392a9899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
