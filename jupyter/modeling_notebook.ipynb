{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827fa7e0-78d7-4cc7-bd7c-6bc5c1156c2e",
   "metadata": {},
   "source": [
    "# Part 1: (Select models and train on our data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110738ee-305c-4fd8-a252-aa459488214d",
   "metadata": {},
   "source": [
    "The concept here is to actually build 3 different models to demonstrate understanding in the class as well as have multiple options to compare for accuracy. If we have time I would also like to do a 4th with a Neural network to compare modern tech against classsic machine learning accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b56304-5d4e-4368-bd24-6012d8f849b0",
   "metadata": {},
   "source": [
    "### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc8802a9-02ec-4c3c-8ac7-ccdeb05ec0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87        33\n",
      "           1       0.91      0.74      0.82        27\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.86      0.84      0.84        60\n",
      "weighted avg       0.86      0.85      0.85        60\n",
      "\n",
      "Trained model saved to ../models/logistic_regression/logistic_regression_model.joblib\n",
      "Preprocessor saved to ../models/logistic_regression/preprocessor.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from joblib import dump\n",
    "\n",
    "# Create a dedicated folder for the logistic regression model\n",
    "model_folder = '../models/logistic_regression/'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# File paths for model and preprocessor\n",
    "model_output_path = os.path.join(model_folder, 'logistic_regression_model.joblib')\n",
    "preprocessor_output_path = os.path.join(model_folder, 'preprocessor.joblib')\n",
    "\n",
    "# File paths for processed data\n",
    "training_data_path = '../data_processed/all_states/all_states_training.csv'\n",
    "validation_data_path = '../data_processed/all_states/all_states_validation.csv'\n",
    "\n",
    "# Load the training and validation datasets\n",
    "train_data = pd.read_csv(training_data_path)\n",
    "val_data = pd.read_csv(validation_data_path)\n",
    "\n",
    "# Separate features and target for training and validation\n",
    "X_train = train_data.drop(columns=['Election Result'])\n",
    "y_train = train_data['Election Result']\n",
    "X_val = val_data.drop(columns=['Election Result'])\n",
    "y_val = val_data['Election Result']\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_features = ['State']\n",
    "numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "# One-Hot Encode the State feature and scale numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),  # Scale numerical data\n",
    "        ('cat', OneHotEncoder(), categorical_features)  # One-hot encode 'State'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply transformations to both training and validation datasets\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_transformed)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Save the trained model\n",
    "dump(model, model_output_path)\n",
    "print(f\"Trained model saved to {model_output_path}\")\n",
    "\n",
    "# Save the fitted preprocessor\n",
    "dump(preprocessor, preprocessor_output_path)\n",
    "print(f\"Preprocessor saved to {preprocessor_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba23bf-a94a-4662-84e4-7c821f0d0e10",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d355c87-ccbe-41cb-b945-857190dbd90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85        33\n",
      "           1       0.90      0.67      0.77        27\n",
      "\n",
      "    accuracy                           0.82        60\n",
      "   macro avg       0.84      0.80      0.81        60\n",
      "weighted avg       0.83      0.82      0.81        60\n",
      "\n",
      "Trained model saved to ../models/k_nearest_neighbors/k_nearest_neighbors_model.joblib\n",
      "Preprocessor saved to ../models/k_nearest_neighbors/preprocessor.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from joblib import dump\n",
    "\n",
    "# Create a dedicated folder for the k-NN model\n",
    "model_folder = '../models/k_nearest_neighbors/'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# File paths for model and preprocessor\n",
    "model_output_path = os.path.join(model_folder, 'k_nearest_neighbors_model.joblib')\n",
    "preprocessor_output_path = os.path.join(model_folder, 'preprocessor.joblib')\n",
    "\n",
    "# File paths for processed data\n",
    "training_data_path = '../data_processed/all_states/all_states_training.csv'\n",
    "validation_data_path = '../data_processed/all_states/all_states_validation.csv'\n",
    "\n",
    "# Load the training and validation datasets\n",
    "train_data = pd.read_csv(training_data_path)\n",
    "val_data = pd.read_csv(validation_data_path)\n",
    "\n",
    "# Separate features and target for training and validation\n",
    "X_train = train_data.drop(columns=['Election Result'])\n",
    "y_train = train_data['Election Result']\n",
    "X_val = val_data.drop(columns=['Election Result'])\n",
    "y_val = val_data['Election Result']\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_features = ['State']\n",
    "numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "# One-Hot Encode the State feature and scale numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),  # Scale numerical data\n",
    "        ('cat', OneHotEncoder(), categorical_features)  # One-hot encode 'State'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply transformations to both training and validation datasets\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "\n",
    "# Create and train the k-NN model\n",
    "k = 3  # Number of neighbors; adjust based on tuning\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_transformed)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Save the trained model\n",
    "dump(model, model_output_path)\n",
    "print(f\"Trained model saved to {model_output_path}\")\n",
    "\n",
    "# Save the fitted preprocessor\n",
    "dump(preprocessor, preprocessor_output_path)\n",
    "print(f\"Preprocessor saved to {preprocessor_output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18597e3-5a7a-491d-824e-88d361f64750",
   "metadata": {},
   "source": [
    "### Decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2792ef99-aae1-44ec-80be-c6e1d8694d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68        33\n",
      "           1       0.59      0.48      0.53        27\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.61      0.60      0.60        60\n",
      "weighted avg       0.61      0.62      0.61        60\n",
      "\n",
      "Trained model saved to ../models/decision_tree/decision_tree_model.joblib\n",
      "Preprocessor saved to ../models/decision_tree/preprocessor.joblib\n",
      "\n",
      "Decision Tree Structure:\n",
      "|--- % with Bachelor's Degree or Higher <= 0.41\n",
      "|   |--- % with Bachelor's Degree or Higher <= -1.15\n",
      "|   |   |--- class: 0\n",
      "|   |--- % with Bachelor's Degree or Higher >  -1.15\n",
      "|   |   |--- Population <= -0.77\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- Population >  -0.77\n",
      "|   |   |   |--- Population <= -0.68\n",
      "|   |   |   |   |--- % Without Healthcare Coverage <= -0.17\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- % Without Healthcare Coverage >  -0.17\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- Population >  -0.68\n",
      "|   |   |   |   |--- Electoral College Votes <= 0.49\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- Electoral College Votes >  0.49\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|--- % with Bachelor's Degree or Higher >  0.41\n",
      "|   |--- % Without Healthcare Coverage <= -0.75\n",
      "|   |   |--- class: 1\n",
      "|   |--- % Without Healthcare Coverage >  -0.75\n",
      "|   |   |--- Nationwide Inflation (%) <= -0.67\n",
      "|   |   |   |--- State_Maine <= 0.50\n",
      "|   |   |   |   |--- Unemployment Rate (%) <= 0.18\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- Unemployment Rate (%) >  0.18\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- State_Maine >  0.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- Nationwide Inflation (%) >  -0.67\n",
      "|   |   |   |--- Unemployment Rate (%) <= -0.69\n",
      "|   |   |   |   |--- % Without Healthcare Coverage <= 0.00\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- % Without Healthcare Coverage >  0.00\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- Unemployment Rate (%) >  -0.69\n",
      "|   |   |   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from joblib import dump\n",
    "\n",
    "# Create a dedicated folder for the Decision Tree model\n",
    "model_folder = '../models/decision_tree/'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# File paths for model and preprocessor\n",
    "model_output_path = os.path.join(model_folder, 'decision_tree_model.joblib')\n",
    "preprocessor_output_path = os.path.join(model_folder, 'preprocessor.joblib')\n",
    "\n",
    "# File paths for processed data\n",
    "training_data_path = '../data_processed/all_states/all_states_training.csv'\n",
    "validation_data_path = '../data_processed/all_states/all_states_validation.csv'\n",
    "\n",
    "# Load the training and validation datasets\n",
    "train_data = pd.read_csv(training_data_path)\n",
    "val_data = pd.read_csv(validation_data_path)\n",
    "\n",
    "# Separate features and target for training and validation\n",
    "X_train = train_data.drop(columns=['Election Result'])\n",
    "y_train = train_data['Election Result']\n",
    "X_val = val_data.drop(columns=['Election Result'])\n",
    "y_val = val_data['Election Result']\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_features = ['State']\n",
    "numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "# One-Hot Encode the State feature and scale numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),  # Scale numerical data\n",
    "        ('cat', OneHotEncoder(), categorical_features)  # One-hot encode 'State'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply transformations to both training and validation datasets\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "\n",
    "# Create and train the Decision Tree model\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)  # Adjust `max_depth` for tree complexity\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_transformed)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Save the trained model\n",
    "dump(model, model_output_path)\n",
    "print(f\"Trained model saved to {model_output_path}\")\n",
    "\n",
    "# Save the fitted preprocessor\n",
    "dump(preprocessor, preprocessor_output_path)\n",
    "print(f\"Preprocessor saved to {preprocessor_output_path}\")\n",
    "\n",
    "# Visualize the tree structure\n",
    "# Ensure feature names are aligned with the one-hot encoding\n",
    "feature_names = (\n",
    "    numerical_features + \n",
    "    list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
    ")\n",
    "print(\"\\nDecision Tree Structure:\")\n",
    "print(export_text(model, feature_names=feature_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f960209-f50e-4e24-a3bb-8a0337d660dd",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf61283-88f1-4e4f-ab2a-a3844486a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]  # For ROC and AUC\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Democrat', 'Republican']))\n",
    "\n",
    "# Calculate AUC\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "auc_rf = auc(fpr_rf, tpr_rf)\n",
    "print(f\"Random Forest AUC: {auc_rf:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "ConfusionMatrixDisplay.from_estimator(rf_model, X_test, y_test, display_labels=['Democrat', 'Republican'])\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "feature_importances = pd.DataFrame(\n",
    "    rf_model.feature_importances_,\n",
    "    index=feature_names,\n",
    "    columns=['Importance']\n",
    ").sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importances)\n",
    "\n",
    "# Cross-Validation Scores\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290ed928-87ba-485c-9e1d-4cf5f2d2c669",
   "metadata": {},
   "source": [
    "# Part 2: (Compare the models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7949cec-8d93-4238-8d7a-f66c9c8a6452",
   "metadata": {},
   "source": [
    "The concept here is to use the metrics covered in class to evaluate model performance and compare/contrast the models we chose to test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf9e32-0691-4dda-8281-a4b9a4990f76",
   "metadata": {},
   "source": [
    "### Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844bde0-1e10-4b39-b543-5abe457678fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print confusion matrix with labels\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap=\"Blues\", values_format='d')  # Format as integers\n",
    "plt.title(\"Confusion Matrix for Election Result Prediction\")\n",
    "plt.show()\n",
    "\n",
    "# Additional performance metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6da5e-067d-469f-a0ac-5d6db70b82c0",
   "metadata": {},
   "source": [
    "### Accuracy, Precision, Recall, F1-Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c583da69-9d00-4d94-a361-1fbe538e1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Democrat', 'Republican']))\n",
    "\n",
    "# Individual metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='D')  # Assuming 'D' represents Democrat\n",
    "recall = recall_score(y_test, y_pred, pos_label='D')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='D')\n",
    "\n",
    "# Print individual metrics\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Democrat): {precision:.4f}\")\n",
    "print(f\"Recall (Democrat): {recall:.4f}\")\n",
    "print(f\"F1-Score (Democrat): {f1:.4f}\")\n",
    "\n",
    "# Note: Add metrics for 'Republican' as well if needed\n",
    "precision_r = precision_score(y_test, y_pred, pos_label='R')\n",
    "recall_r = recall_score(y_test, y_pred, pos_label='R')\n",
    "f1_r = f1_score(y_test, y_pred, pos_label='R')\n",
    "\n",
    "print(f\"\\nPrecision (Republican): {precision_r:.4f}\")\n",
    "print(f\"Recall (Republican): {recall_r:.4f}\")\n",
    "print(f\"F1-Score (Republican): {f1_r:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7272940-9084-4856-a94b-294bc2d745ee",
   "metadata": {},
   "source": [
    "### ROC Curve and AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a383e3-11d5-4301-8ae9-8599e966b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get probabilities for the positive class (e.g., 'Democrat' or class 1)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Ensure class probabilities are available\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob, pos_label='D')  # Adjust pos_label for your positive class\n",
    "auc_score = auc(fpr, tpr)\n",
    "\n",
    "# Print AUC\n",
    "print(f\"AUC: {auc_score:.4f}\")\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b3d95-b62b-4297-aae3-53c5a20dd82c",
   "metadata": {},
   "source": [
    "# Part 3: (compare a modern neural network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b0400-6a8a-48c9-beb3-6c9beefa48b9",
   "metadata": {},
   "source": [
    "The concept here is to run the data on a third model (Binary Classification Neural Network) to see if modern neural networks can outperform classic machine learning tasks on relatively simple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaaba4a-3383-4e47-a387-7973069f0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('your_dataset.csv')  # Replace with the path to your dataset\n",
    "\n",
    "# Feature engineering\n",
    "X = data.drop(columns=[\"Election Result\", \"State\"])  # Features\n",
    "y = data[\"Election Result\"].apply(lambda x: 1 if x == \"D\" else 0)  # Binary target\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "categorical_features = [\"In Recession\"]\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_features),\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X_preprocessed.toarray(), dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network\n",
    "class ElectionPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ElectionPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)  # First hidden layer with 32 neurons\n",
    "        self.fc2 = nn.Linear(32, 16)         # Second hidden layer with 16 neurons\n",
    "        self.fc3 = nn.Linear(16, 1)          # Output layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "model = ElectionPredictor(input_size)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train).squeeze()\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).squeeze()\n",
    "    y_pred_classes = (y_pred > 0.5).int()\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_classes, target_names=['Republican', 'Democrat']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5dfe3-2189-4db2-9e2b-ccd78fb1a989",
   "metadata": {},
   "source": [
    "### Evaluate for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c1bb6-6977-4da2-8cf9-225d7c71aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, classification_report\n",
    "\n",
    "# Assuming `y_test` is the true labels and `y_prob` is the predicted probabilities from the neural network\n",
    "\n",
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Neural Network Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Democrat', 'Republican']))\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "auc_score = auc(fpr, tpr)\n",
    "\n",
    "print(f\"Neural Network Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Neural Network Precision: {precision:.4f}\")\n",
    "print(f\"Neural Network Recall: {recall:.4f}\")\n",
    "print(f\"Neural Network F1 Score: {f1:.4f}\")\n",
    "print(f\"Neural Network AUC: {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108071c0-0f08-4922-8ebc-2f7e6698e5c3",
   "metadata": {},
   "source": [
    "### Compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62ecb3a-47b7-46d7-a851-f130378d6f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
